{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37d4481f",
   "metadata": {},
   "source": [
    "# Simple RAG System with Table Extraction and Query Enhancement\n",
    "\n",
    "A streamlined RAG system with essential features:\n",
    "- Table detection and description\n",
    "- Query rewriting for better retrieval\n",
    "- Hybrid retrieval from German business reports\n",
    "- Simple setup and execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23aac632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.23)\n",
      "Requirement already satisfied: langchain-google-genai in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.1.5)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.56 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.3.65)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (1.4.54)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (3.10.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.3.45)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-google-genai) (0.6.18)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-google-genai) (2.11.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (4.48.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.24.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.36.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.66.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.73.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9)\n",
      "Requirement already satisfied: anyio in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.56->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\joe\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pds-py (c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pds-py (c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pds-py (c:\\users\\joe\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "!pip install langchain-community langchain-google-genai faiss-cpu sentence-transformers python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df82abc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "print(\"✅ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba6b9231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe\\AppData\\Local\\Temp\\ipykernel_3288\\2265927161.py:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration set\n"
     ]
    }
   ],
   "source": [
    "# Simple configuration\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "MARKDOWN_FOLDER = \"./Extrahierter_Text_Markdown\"\n",
    "VECTOR_STORE_PATH = \"./faiss_index\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "\n",
    "# Initialize models\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.1, google_api_key=GOOGLE_API_KEY)\n",
    "\n",
    "print(\"✅ Configuration set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f3e90c",
   "metadata": {},
   "source": [
    "## Table Detection and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b60fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Table functions ready\n"
     ]
    }
   ],
   "source": [
    "def detect_tables(text: str) -> List[str]:\n",
    "    \"\"\"Simple table detection\"\"\"\n",
    "    tables = []\n",
    "    \n",
    "    # Markdown tables\n",
    "    table_pattern = r'(\\|[^\\n]*\\|\\s*\\n\\|[-\\s\\|:]+\\|\\s*\\n(?:\\|[^\\n]*\\|\\s*\\n?)*)'\n",
    "    tables.extend(re.findall(table_pattern, text, re.MULTILINE))\n",
    "    \n",
    "    # Financial data blocks\n",
    "    financial_pattern = r'((?:in Mio\\. €|in %|in Tsd\\.|€ Mio\\.|Mio\\. EUR)[^\\n]*\\n(?:[^\\n]*\\d+[^\\n]*\\n?)+)'\n",
    "    tables.extend(re.findall(financial_pattern, text, re.MULTILINE))\n",
    "    \n",
    "    return tables\n",
    "\n",
    "def describe_table(table_text: str) -> str:\n",
    "    \"\"\"Generate table description using LLM\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Beschreibe diese Tabelle/Daten in 1-2 Sätzen auf Deutsch:\\n{table}\\n\\nBeschreibung:\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "        description = chain.invoke({\"table\": table_text})\n",
    "        return description.strip()\n",
    "    except:\n",
    "        return \"Tabelle mit Finanz- oder Geschäftsdaten.\"\n",
    "\n",
    "print(\"✅ Table functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c01614",
   "metadata": {},
   "source": [
    "## Query Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8f50ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Query enhancement ready\n"
     ]
    }
   ],
   "source": [
    "def enhance_query(query: str) -> List[str]:\n",
    "    \"\"\"Rewrite query for better retrieval\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Erstelle 3 alternative Suchbegriffe für diese Frage in deutschen Geschäftsberichten:\\n\"\n",
    "        \"'{query}'\\n\\n\"\n",
    "        \"Gib nur die 3 Alternativen zurück, eine pro Zeile:\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "        response = chain.invoke({\"query\": query})\n",
    "        alternatives = [line.strip() for line in response.split('\\n') if line.strip()]\n",
    "        return [query] + alternatives[:3]  # Original + 3 alternatives\n",
    "    except:\n",
    "        return [query]  # Return original if enhancement fails\n",
    "\n",
    "print(\"✅ Query enhancement ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f1306",
   "metadata": {},
   "source": [
    "## Document Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ca90d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Document processing ready\n"
     ]
    }
   ],
   "source": [
    "def process_document(file_path: str) -> List[Document]:\n",
    "    \"\"\"Process single markdown file with table enhancement\"\"\"\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Get filename info\n",
    "    filename = Path(file_path).stem\n",
    "    company = filename.replace('_2023', '').replace('_', ' ')\n",
    "    \n",
    "    # Detect and describe tables\n",
    "    tables = detect_tables(content)\n",
    "    \n",
    "    # Add table descriptions to content\n",
    "    enhanced_content = content\n",
    "    for table in tables:\n",
    "        description = describe_table(table)\n",
    "        enhanced_content += f\"\\n\\n[Tabellenbeschreibung]: {description}\\n\"\n",
    "    \n",
    "    # Split into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_text(enhanced_content)\n",
    "    \n",
    "    # Create documents\n",
    "    documents = []\n",
    "    for chunk in chunks:\n",
    "        doc = Document(\n",
    "            page_content=chunk,\n",
    "            metadata={'company': company, 'source': filename}\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "def process_all_documents() -> List[Document]:\n",
    "    \"\"\"Process all markdown files\"\"\"\n",
    "    \n",
    "    markdown_files = list(Path(MARKDOWN_FOLDER).glob('*.md'))\n",
    "    print(f\"Found {len(markdown_files)} files\")\n",
    "    \n",
    "    all_documents = []\n",
    "    \n",
    "    for file_path in markdown_files:\n",
    "        print(f\"Processing {file_path.name}...\")\n",
    "        try:\n",
    "            documents = process_document(str(file_path))\n",
    "            all_documents.extend(documents)\n",
    "            print(f\"  → {len(documents)} chunks\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error: {e}\")\n",
    "    \n",
    "    print(f\"Total: {len(all_documents)} documents\")\n",
    "    return all_documents\n",
    "\n",
    "print(\"✅ Document processing ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d49ad",
   "metadata": {},
   "source": [
    "## Vector Store Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa17f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new vector store...\n",
      "Found 1 files\n",
      "Processing BMW_2023.md...\n",
      "  → 1650 chunks\n",
      "Total: 1650 documents\n"
     ]
    }
   ],
   "source": [
    "# Create or load vector store\n",
    "def load_or_create_vectorstore():\n",
    "    \"\"\"Load existing or create new vector store\"\"\"\n",
    "    \n",
    "    # Check if vector store exists\n",
    "    if (os.path.exists(VECTOR_STORE_PATH) and \n",
    "        os.path.exists(os.path.join(VECTOR_STORE_PATH, \"index.faiss\"))):\n",
    "        \n",
    "        print(\"Loading existing vector store...\")\n",
    "        try:\n",
    "            vectorstore = FAISS.load_local(\n",
    "                VECTOR_STORE_PATH, \n",
    "                embeddings, \n",
    "                allow_dangerous_deserialization=True\n",
    "            )\n",
    "            print(\"✅ Vector store loaded\")\n",
    "            return vectorstore\n",
    "        except:\n",
    "            print(\"Failed to load, creating new...\")\n",
    "    \n",
    "    # Create new vector store\n",
    "    print(\"Creating new vector store...\")\n",
    "    documents = process_all_documents()\n",
    "    \n",
    "    if not documents:\n",
    "        print(\"❌ No documents found\")\n",
    "        return None\n",
    "    \n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    vectorstore.save_local(VECTOR_STORE_PATH)\n",
    "    print(\"✅ Vector store created\")\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "# Initialize vector store\n",
    "vectorstore = load_or_create_vectorstore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6259cb98",
   "metadata": {},
   "source": [
    "## Hybrid Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad5eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_retrieve(query: str, k: int = 5) -> List[Document]:\n",
    "    \"\"\"Retrieve using multiple query variants\"\"\"\n",
    "    \n",
    "    if not vectorstore:\n",
    "        return []\n",
    "    \n",
    "    # Get enhanced queries\n",
    "    enhanced_queries = enhance_query(query)\n",
    "    print(f\"Searching with {len(enhanced_queries)} query variants...\")\n",
    "    \n",
    "    all_results = []\n",
    "    seen_content = set()\n",
    "    \n",
    "    # Search with each query variant\n",
    "    for enhanced_query in enhanced_queries:\n",
    "        try:\n",
    "            results = vectorstore.similarity_search(enhanced_query, k=k)\n",
    "            \n",
    "            for doc in results:\n",
    "                # Avoid duplicates\n",
    "                content_hash = hash(doc.page_content[:100])\n",
    "                if content_hash not in seen_content:\n",
    "                    all_results.append(doc)\n",
    "                    seen_content.add(content_hash)\n",
    "        except Exception as e:\n",
    "            print(f\"Search error: {e}\")\n",
    "    \n",
    "    return all_results[:k*2]  # Return more for better context\n",
    "\n",
    "print(\"✅ Hybrid retrieval ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e8f24",
   "metadata": {},
   "source": [
    "## RAG Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae8219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str) -> Dict:\n",
    "    \"\"\"Answer question using RAG\"\"\"\n",
    "    \n",
    "    # Retrieve relevant documents\n",
    "    docs = hybrid_retrieve(question)\n",
    "    \n",
    "    if not docs:\n",
    "        return {\n",
    "            'answer': 'Keine relevanten Informationen gefunden.',\n",
    "            'sources': []\n",
    "        }\n",
    "    \n",
    "    # Prepare context\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"[{doc.metadata['company']}]: {doc.page_content}\"\n",
    "        for doc in docs[:8]  # Limit context\n",
    "    ])\n",
    "    \n",
    "    # Create RAG prompt\n",
    "    rag_prompt = ChatPromptTemplate.from_template(\n",
    "        \"Beantworte die Frage basierend auf dem Kontext aus deutschen Geschäftsberichten.\\n\\n\"\n",
    "        \"Kontext:\\n{context}\\n\\n\"\n",
    "        \"Frage: {question}\\n\\n\"\n",
    "        \"Antwort:\"\n",
    "    )\n",
    "    \n",
    "    # Generate answer\n",
    "    try:\n",
    "        chain = rag_prompt | llm | StrOutputParser()\n",
    "        answer = chain.invoke({\n",
    "            'context': context,\n",
    "            'question': question\n",
    "        })\n",
    "        \n",
    "        # Extract sources\n",
    "        sources = list(set([doc.metadata['company'] for doc in docs[:5]]))\n",
    "        \n",
    "        return {\n",
    "            'answer': answer.strip(),\n",
    "            'sources': sources\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'answer': f'Fehler bei der Antwortgenerierung: {e}',\n",
    "            'sources': []\n",
    "        }\n",
    "\n",
    "print(\"✅ RAG system ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27859c3",
   "metadata": {},
   "source": [
    "## Test the System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a2e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample questions\n",
    "test_questions = [\n",
    "    \"Wie hat sich der Umsatz von BMW entwickelt?\",\n",
    "    \"Was sind die wichtigsten Kennzahlen von Volkswagen?\",\n",
    "    \"Welche Informationen gibt es über Elektromobilität?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Frage: {question}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    result = answer_question(question)\n",
    "    \n",
    "    print(f\"\\nAntwort:\")\n",
    "    print(result['answer'])\n",
    "    \n",
    "    print(f\"\\nQuellen: {', '.join(result['sources'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fda7df",
   "metadata": {},
   "source": [
    "## Interactive Query Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c303adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple interactive interface\n",
    "def interactive_rag():\n",
    "    \"\"\"Simple question-answer interface\"\"\"\n",
    "    \n",
    "    print(\"\\n🤖 RAG System für deutsche Geschäftsberichte\")\n",
    "    print(\"Geben Sie 'quit' ein zum Beenden.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        question = input(\"❓ Ihre Frage: \").strip()\n",
    "        \n",
    "        if question.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"Auf Wiedersehen!\")\n",
    "            break\n",
    "        \n",
    "        if not question:\n",
    "            continue\n",
    "        \n",
    "        print(\"\\n🔍 Suche...\")\n",
    "        result = answer_question(question)\n",
    "        \n",
    "        print(f\"\\n💡 Antwort:\")\n",
    "        print(result['answer'])\n",
    "        \n",
    "        if result['sources']:\n",
    "            print(f\"\\n📚 Quellen: {', '.join(result['sources'])}\")\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Start interactive mode\n",
    "interactive_rag()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b735fd",
   "metadata": {},
   "source": [
    "## System Summary\n",
    "\n",
    "This simplified RAG system includes:\n",
    "- ✅ Table detection and description\n",
    "- ✅ Query enhancement for better retrieval\n",
    "- ✅ Hybrid retrieval with multiple query variants\n",
    "- ✅ Simple document processing\n",
    "- ✅ Streamlined configuration\n",
    "\n",
    "No complex error handling, minimal configuration, straightforward execution!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
